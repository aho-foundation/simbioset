"""FastAPI routes for Chat API."""

import time
from datetime import datetime
from typing import List, Dict, Optional

from fastapi import APIRouter, HTTPException, Request, Response, status, Body
from pydantic import BaseModel

from api.logger import root_logger as logger
from api.detect.web_search import web_search_service
from api.chat.models import ChatSession, ChatSessionCreate, ChatMessageCreate, ChatDragToChat
from api.chat.service import chat_session_service, generate_starters


class LocalizeRequest(BaseModel):
    sessionId: str
    latitude: float
    longitude: float
    conversationText: str
    action: Optional[str] = "localize"  # "localize", "expand_context", "new_branch"


from api.kb.models import ConceptNode
from api.kb.service import KBService
from api.storage.paragraph_service import ParagraphService
from api.llm import LLMPermanentError, LLMTemporaryError, call_llm
from api.sessions import session_manager
from api.logger import root_logger
import re

log = root_logger.debug
from api.chat.context_builder import (
    build_context_for_llm,
    should_include_context,
    get_weather_context,
    extract_ecosystem_and_location,
    format_ecosystem_context,
)
from api.detect.localize import reverse_geocode_location

router = APIRouter(prefix="/api/chat", tags=["Chat"])

# Services will be injected from app.state in route handlers

# Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ LLM Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ Ð² Ð¿Ñ€Ð¾ÐºÑÐ¸ (llm_proxy)
# ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¸ÑÐºÐ°Ð¶ÐµÐ½Ð½Ñ‹Ñ… ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ Ð² call_llm


def remove_sources_section_from_content(content: str) -> str:
    """
    Ð£Ð´Ð°Ð»ÑÐµÑ‚ Ñ€Ð°Ð·Ð´ÐµÐ» "## Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸" Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð° LLM.

    Ð­Ñ‚Ð¾ Ð¿Ñ€ÐµÐ´Ð¾Ñ‚Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð´ÑƒÐ±Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² - Ð¾Ð½Ð¸ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÑŽÑ‚ÑÑ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾,
    Ð° Ð½Ðµ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ.

    Args:
        content: ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð° LLM

    Returns:
        Ð¢ÐµÐºÑÑ‚ Ð±ÐµÐ· Ñ€Ð°Ð·Ð´ÐµÐ»Ð° Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð²
    """
    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ñ€Ð°Ð·Ð´ÐµÐ» "## Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸" Ð² Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð°Ñ…:
    # - ## Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸
    # - ## Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸:
    # - ### Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸
    # - Ð¡ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ¾Ð¼ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð¸Ð»Ð¸ Ð±ÐµÐ·
    patterns = [
        # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ñ ## Ð¸Ð»Ð¸ ###, Ñ Ð´Ð²Ð¾ÐµÑ‚Ð¾Ñ‡Ð¸ÐµÐ¼ Ð¸Ð»Ð¸ Ð±ÐµÐ·, Ð¸ Ð²ÑÐµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ Ð´Ð¾ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ° Ð¸Ð»Ð¸ ÐºÐ¾Ð½Ñ†Ð°
        r"\n?##+\s*Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸:?\s*\n.*?(?=\n?##+|\Z)",
        # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸
        r"^##+\s*Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸:?\s*\n.*?(?=\n?##+|\Z)",
        # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð² ÑÐµÑ€ÐµÐ´Ð¸Ð½Ðµ Ñ‚ÐµÐºÑÑ‚Ð°
        r"\n##+\s*Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸:?\s*\n.*?(?=\n##+|\n###+|\Z)",
    ]

    cleaned_content = content
    for pattern in patterns:
        cleaned_content = re.sub(pattern, "", cleaned_content, flags=re.DOTALL | re.IGNORECASE | re.MULTILINE)

    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð² ÐºÐ¾Ð½Ñ†Ðµ
    return cleaned_content.strip()


def parse_sources_from_response(response_content: str) -> List[Dict[str, str]]:
    """
    ÐŸÐ°Ñ€ÑÐ¸Ñ‚ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° LLM Ñ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ñ„Ð°Ð»Ð»Ð±ÐµÐºÐ°Ð¼Ð¸.

    Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¸Ñ‰ÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ€Ð°Ð·Ð´ÐµÐ» "## Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸", Ð·Ð°Ñ‚ÐµÐ¼ Ð¿Ñ‹Ñ‚Ð°ÐµÑ‚ÑÑ
    Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° Ð² Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð°Ñ….

    Args:
        response_content: ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð° LLM

    Returns:
        Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÐ»Ð¾Ð²Ð°Ñ€ÐµÐ¹ Ñ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°Ð¼Ð¸ [{'title': 'ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°', 'type': 'Ð¢Ð¸Ð¿ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°', 'url': 'ÑÑÑ‹Ð»ÐºÐ°'}]
    """
    sources: List[Dict[str, str]] = []

    # Ð¤ÐÐ›Ð›Ð‘Ð•Ðš 1: Ð˜Ñ‰ÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ€Ð°Ð·Ð´ÐµÐ» "## Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸"
    sources_match = re.search(
        r"##\s*Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸?\s*\n(.*?)(?=\n##|\n###|\Z)", response_content, re.DOTALL | re.IGNORECASE
    )

    if sources_match:
        sources_text = sources_match.group(1).strip()
        # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð¿Ñ€Ð¾Ð½ÑƒÐ¼ÐµÑ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð²
        lines = sources_text.split("\n")
        for line in lines:
            line = line.strip()
            if not line:
                continue

            # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð½ÑƒÐ¼ÐµÑ€Ð°Ñ†Ð¸ÑŽ Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ (1., 2., etc.)
            line = re.sub(r"^\d+\.\s*", "", line)

            # Ð˜Ñ‰ÐµÐ¼ URL Ð² ÑÑ‚Ñ€Ð¾ÐºÐµ (https://... Ð¸Ð»Ð¸ http://...)
            url_match = re.search(r'(https?://[^\s]+)', line)
            url = url_match.group(1) if url_match else None

            # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ URL Ð¸Ð· ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð´Ð»Ñ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð¸ Ñ‚Ð¸Ð¿Ð°
            line_without_url = re.sub(r'\s*https?://[^\s]+\s*', '', line).strip()

            # Ð Ð°Ð·Ð´ÐµÐ»ÑÐµÐ¼ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¸ Ñ‚Ð¸Ð¿ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð² ÑÐºÐ¾Ð±ÐºÐ°Ñ…)
            type_match = re.search(r"\(([^)]+)\)$", line_without_url)
            if type_match:
                title = line_without_url[: type_match.start()].strip()
                source_type = type_match.group(1).strip()
                # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ñ Ñ‚Ð¸Ð¿Ð¾Ð¼ "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ‚Ð¸Ð¿"
                if source_type.lower() in ("Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ‚Ð¸Ð¿", "unknown type", "unknown"):
                    continue
            else:
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð° ÑÐ¼Ð¾Ð´Ð¶Ð¸ Ð² ÐºÐ¾Ð½Ñ†Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸ (Ð¿Ð¾ÑÐ»Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ)
                emoji_match = re.search(r'([^\w\s])\s*$', line_without_url)
                if emoji_match:
                    title = line_without_url[:emoji_match.start()].strip()
                    source_type = emoji_match.group(1).strip()
                else:
                    # Ð•ÑÐ»Ð¸ Ñ‚Ð¸Ð¿ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº
                    continue

            # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ñ Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¼ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð¸ Ñ‚Ð¸Ð¿Ð¾Ð¼
            if title and source_type:
                source_dict = {"title": title, "type": source_type}
                if url:
                    source_dict["url"] = url
                sources.append(source_dict)

    # Ð¤ÐÐ›Ð›Ð‘Ð•Ðš 2: Ð˜Ñ‰ÐµÐ¼ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ Ñ‚Ð¸Ð¿Ð¾Ð² Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² Ð² Ñ‚ÐµÐºÑÑ‚Ðµ
    if not sources:
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð²
        source_type_patterns = {
            'Ð½Ð°ÑƒÑ‡Ð½Ð°Ñ Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°': 'ÐÐ°ÑƒÑ‡Ð½Ð°Ñ Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°',
            'scientific literature': 'ÐÐ°ÑƒÑ‡Ð½Ð°Ñ Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°',
            'Ð²ÐµÐ±-Ð¿Ð¾Ð¸ÑÐº': 'Ð’ÐµÐ±-Ð¿Ð¾Ð¸ÑÐº',
            'web search': 'Ð’ÐµÐ±-Ð¿Ð¾Ð¸ÑÐº',
            'Ð±Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹': 'Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹',
            'knowledge base': 'Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹',
            'Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ': 'ÐÐµÐ¹Ñ€Ð¾Ð½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ',
            'neural network': 'ÐÐµÐ¹Ñ€Ð¾Ð½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ',
            'ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ': 'Ð­ÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ',
            'expert knowledge': 'Ð­ÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ',
            'Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ñ': 'ÐŸÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ñ',
            'publication': 'ÐŸÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ñ',
            'Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ': 'Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ',
            'research': 'Ð˜ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ðµ'
        }

        found_types = []
        content_lower = response_content.lower()

        for pattern, source_type in source_type_patterns.items():
            if pattern in content_lower and source_type not in found_types:
                found_types.append(source_type)

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ñ‚Ð¸Ð¿Ð¾Ð²
        for i, source_type in enumerate(found_types, 1):
            title = f"{source_type} Ð¿Ð¾ ÑÐ¸Ð¼Ð±Ð¸Ð¾Ð·Ñƒ"  # Ð”ÐµÑ„Ð¾Ð»Ñ‚Ð½Ñ‹Ð¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
            sources.append({"title": title, "type": source_type})

    # Ð¤ÐÐ›Ð›Ð‘Ð•Ðš 3: Ð•ÑÐ»Ð¸ Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾, Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸
    if not sources:
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ð´Ð»Ñ ÑÐ¸Ð¼Ð±Ð¸Ð¾Ð·Ð°
        sources = [
            {"title": "Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð¿Ð¾ ÑÐ¸Ð¼Ð±Ð¸Ð¾Ð·Ñƒ", "type": "Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹"},
            {"title": "Ð­ÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ", "type": "Ð­ÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ"}
        ]

    return sources


@router.post("/session", response_model=ChatSession)
async def create_chat_session(session_data: ChatSessionCreate):
    """
    Create a new chat session.

    Creates a new chat session.
    """
    try:
        # Create a new chat session
        session = chat_session_service.create_session(session_data)

        # If ecosystem data is provided, set up the session location
        if session_data.ecosystem:
            ecosystem_data = {
                "location": session_data.ecosystem.get("coordinates", {}),
                "ecosystems": [
                    {"name": session_data.ecosystem.get("type", "Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ ÑÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ð°"), "scale": "regional"}
                ],
                "coordinates": session_data.ecosystem.get("coordinates"),
                "time_reference": None,
                "source": "branch_creation",
                "parent_session_id": session_data.ecosystem.get("parentSessionId"),
                "artifacts_summary": session_data.ecosystem.get("artifactsSummary"),
            }
            chat_session_service.update_session_location(session.id, ecosystem_data)

        return session
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.post("/message", response_model=dict)
async def send_chat_message(message_data: ChatMessageCreate, request: Request, response: Response):
    """
    Send a message in a chat session.

    Adds the message to the concept tree and potentially generates a response.
    Automatically creates user session if not exists.
    """
    # Check if the message is about symbiosis or related topics to trigger web search
    message_lower = message_data.message.lower()
    trigger_keywords = ["ÑÐ¸Ð¼Ð±Ð¸Ð¾Ð·", "symbiosis", "symbiotic", "ÑÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ð°", "ecosystem", "Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ", "interaction"]
    needs_web_search = any(keyword in message_lower for keyword in trigger_keywords)
    try:
        # Initialize session_id to None to avoid UnboundLocalError
        session_id = None

        # Check if this is a Telegram request with user ID
        telegram_user_id = message_data.context.get("telegram_user_id") if message_data.context else None

        if telegram_user_id:
            # Use persistent session for Telegram user (async)
            session_id = await session_manager.get_or_create_telegram_session(telegram_user_id, message_data.author)
            user_session = await session_manager.get_session(session_id)
        else:
            # Use sessionId from request body if provided, otherwise from cookies
            if message_data.sessionId is not None:
                session_id = message_data.sessionId
                user_session = await session_manager.get_session(session_id)
            else:
                # Try to get session_id from cookies first
                session_id = request.cookies.get("session_id")

                if session_id:
                    # If we have session_id from cookies, get the session (async)
                    user_session = await session_manager.get_session(session_id)
                else:
                    # No session in cookies, create a new one
                    user_session = None

                if not user_session:
                    # Create new session if none exists (async)
                    session_id = await session_manager.create_session(
                        {
                            "user_id": message_data.author,
                            "created_at": "auto",
                            "message_count": 0,
                            "last_activity": datetime.now(),
                        }
                    )
                    response.set_cookie("session_id", session_id, httponly=True, max_age=2592000)  # 30 days
                    user_session = await session_manager.get_session(session_id)

        # Update session activity (async)
        if user_session and session_id:
            # Use the correct session_id for updates
            await session_manager.increment_message_count(session_id)

        # Get services from app.state (injected at startup)
        service: KBService = request.app.state.kb_service
        paragraph_service: ParagraphService = request.app.state.paragraph_service

        # Verify the session exists, create if not found or default
        # Note: ChatSession ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ÑÑ Ñ‡ÐµÑ€ÐµÐ· chat_session_service, Ð½Ðµ Ñ‡ÐµÑ€ÐµÐ· ConceptNode
        # ConceptNode Ð¼Ð¾Ð¶ÐµÑ‚ Ð¸Ð¼ÐµÑ‚ÑŒ sessionId, Ð½Ð¾ ÑÐ°Ð¼ Ð½Ðµ ÑÐ²Ð»ÑÐµÑ‚ÑÑ ÑÐµÑÑÐ¸ÐµÐ¹
        session_node = service.get_node(session_id)  # type: ignore
        if not session_node or session_id == "default-session":
            # Create root node for this chat session (system message, not a session itself)
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ ÐºÐ°Ðº ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð³Ð¾ ÑƒÐ·Ð»Ð°
            session_node = service.add_concept(
                parent_id=None,
                content=message_data.message,  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ ÑÑ‚Ð°Ñ€Ñ‚ÐµÑ€Ð°/Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
                role="system",
                node_type="message",  # Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¾: Ð½Ðµ chat_session, Ð° message Ñ role=system
                session_id=None,  # Root node doesn't have sessionId
                category="neutral",
            )
            # Use the new node ID as session identifier
            actual_session_id = session_node.id
        else:
            actual_session_id = session_id  # type: ignore

        # Update chat session message count
        chat_session_service.increment_message_count(actual_session_id)

        # Link chat session to user session if not already linked (async)
        if session_id and user_session and not user_session.get("chat_session_id"):
            user_session["chat_session_id"] = actual_session_id
            await session_manager.update_session(session_id, user_session)

        # Add the user message to the concept tree
        user_message_node = service.add_concept(
            parent_id=actual_session_id,
            content=message_data.message,
            role="user",
            node_type="message",
            session_id=actual_session_id,
        )

        # Parse message to paragraphs and save for FAISS search
        try:
            await paragraph_service.save_chat_message_paragraphs(
                message_content=message_data.message,
                session_id=actual_session_id,
                author=message_data.author,
                author_id=None,  # TODO: Add author_id to ChatMessageCreate model
                timestamp=user_message_node.timestamp,
            )
        except Exception as e:
            # Log error but don't fail the request
            print(f"Error saving message paragraphs: {e}")

        # Load the simbio expert prompt template
        with open("api/prompts/simbio_expert.txt", "r", encoding="utf-8") as f:
            prompt_template = f.read()

        # Prepare context data for the prompt
        context = message_data.context or {}
        local_stat = context.get("local_stat", "")

        # Weaviate handles semantic search for all internal knowledge (artifacts, chats, books) automatically
        # Only external sources (web, books) need explicit search
        websearch_context = await web_search_service.get_symbiosis_context(message_data.message)
        books_search_context = await search_books_for_message(
            message_data.message, web_search_service, actual_session_id
        )

        # Combine only external sources (web and books)
        external_sources = "\n".join(filter(None, [websearch_context, books_search_context]))

        # User observation extraction is now handled by LLM instead of keyword matching

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½ÑƒÑŽ Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ ÑÐµÑÑÐ¸Ð¸
        chat_session = chat_session_service.get_session(actual_session_id)
        session_location_data = chat_session.location if chat_session and chat_session.location else None

        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð»Ð¾ÐºÐ°Ñ†Ð¸ÑŽ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ (ÐµÑÐ»Ð¸ ÑÐ²Ð½Ð¾ ÑƒÐ¿Ð¾Ð¼ÑÐ½ÑƒÑ‚Ð°)
        user_location_data = None
        if message_data.author != "assistant":  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
            try:
                user_location_data = await extract_ecosystem_and_location(message_data.message)
                if user_location_data.get("location"):
                    logger.info(f"ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð° Ð»Ð¾ÐºÐ°Ñ†Ð¸Ñ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {user_location_data.get('location')}")

                    # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ðµ Ð³ÐµÐ¾ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚
                    if user_location_data.get("location"):
                        try:
                            from api.detect.localize import geocode

                            coordinates = geocode(user_location_data["location"])
                            if coordinates:
                                user_location_data["coordinates"] = {
                                    "latitude": coordinates[0],
                                    "longitude": coordinates[1],
                                }
                                logger.info(
                                    f"Ð“ÐµÐ¾ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ Ð´Ð»Ñ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¸ {user_location_data['location']}: {coordinates}"
                                )
                        except Exception as e:
                            logger.warning(
                                f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð³ÐµÐ¾ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð»Ð¾ÐºÐ°Ñ†Ð¸ÑŽ {user_location_data.get('location')}: {e}"
                            )

            except Exception as e:
                logger.warning(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¸ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸: {e}")

        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½ÑƒÑŽ Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ ÑÐµÑÑÐ¸Ð¸ Ð¸Ð»Ð¸ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½ÑƒÑŽ Ð¸Ð· ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
        location = None
        ecosystems = []
        if session_location_data:
            # ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ð¾Ð¹ Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÑÐµÑÑÐ¸Ð¸
            location = session_location_data.get("location")
            ecosystems = session_location_data.get("ecosystems", [])
            logger.info(
                f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½ÑƒÑŽ Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ ÑÐµÑÑÐ¸Ð¸: location={location}, ecosystems={[e.get('name') for e in ecosystems]}"
            )
        elif user_location_data and user_location_data.get("location"):
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð»Ð¾ÐºÐ°Ñ†Ð¸ÑŽ Ð¸Ð· Ñ‚ÐµÐºÑƒÑ‰ÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
            location = user_location_data.get("location")
            ecosystems = user_location_data.get("ecosystems", [])

            # ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÑ‚Ñƒ Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ð² ÑÐµÑÑÐ¸Ð¸
            chat_session_service.update_session_location(
                actual_session_id,
                {
                    "location": location,
                    "ecosystems": ecosystems,
                    "coordinates": user_location_data.get("coordinates"),
                    "time_reference": user_location_data.get("time_reference"),
                    "source": "message_analysis",  # ÐžÑ‚Ð¼ÐµÑ‡Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð° Ð¸Ð· Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
                },
            )
            logger.info(
                f"ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸Ð· ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ: location={location}, ecosystems={[e.get('name') for e in ecosystems]}"
            )

        conversation_summary, recent_messages = await build_context_for_llm(
            actual_session_id, service, location=location, ecosystems=ecosystems
        )

        # Context sections are included if they have content (KISS: no conditional logic needed)

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¿Ð¾Ð³Ð¾Ð´Ðµ, ÐµÑÐ»Ð¸ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹ Ð³Ð¾Ñ€Ð¾Ð´ Ð¸ Ð²Ñ€ÐµÐ¼Ñ
        weather_context = await get_weather_context(message_data.message)

        # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ ÑÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ (Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð¿Ð¾Ð³Ð¾Ð´Ñƒ Ð¸ ÑÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ)
        ecosystem_context = format_ecosystem_context(ecosystems, location, weather=weather_context)

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð³Ñ€Ð°Ñ„Ð¾Ð²Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ‡ÐµÑ€ÐµÐ· ÑÐ¸Ð¼Ð±Ð¸Ð¾Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ²ÑÐ·Ð¸
        # ÐÐ• ÑÑ‚Ñ€Ð¾Ð¸Ð¼ Ð³Ñ€Ð°Ñ„Ð¾Ð²Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð¿ÐµÑ€Ð²Ñ‹Ñ… 2 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ (ÑÑ‚Ð°Ñ€Ñ‚ÐµÑ€ + Ð¾Ñ‚Ð²ÐµÑ‚) - ÑÑ‚Ð¾ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ñ€Ð°Ð½Ð¾
        graph_context = ""
        try:
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ð² ÑÐµÑÑÐ¸Ð¸
            session_messages = service.get_session_messages(actual_session_id)
            message_count = len(session_messages) if session_messages else 0

            # Ð¡Ñ‚Ñ€Ð¾Ð¸Ð¼ Ð³Ñ€Ð°Ñ„Ð¾Ð²Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð² ÑÐµÑÑÐ¸Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐµ 2 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
            # (ÑÑ‚Ð°Ñ€Ñ‚ÐµÑ€ + Ð¾Ñ‚Ð²ÐµÑ‚ = 2 ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ, Ð¿Ð¾ÑÐ»Ðµ ÑÑ‚Ð¾Ð³Ð¾ ÑƒÐ¶Ðµ Ð¼Ð¾Ð¶Ð½Ð¾ ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ Ð³Ñ€Ð°Ñ„)
            if message_count > 2:
                from api.chat.context_builder import build_graph_context

                # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð¾Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ (Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ FAISS Ð¸Ð»Ð¸ Weaviate)
                storage = getattr(request.app.state, "storage", None) or getattr(
                    request.app.state, "faiss_storage", None
                )
                graph_context = await build_graph_context(
                    message=message_data.message,
                    session_id=actual_session_id,
                    db_manager=request.app.state.db_manager,
                    storage=storage,
                    max_depth=2,
                    max_relationships=10,
                )
        except Exception as e:
            print(f"Error building graph context: {e}")

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¸Ð¼Ð±Ð¸Ð¾Ð½Ñ‚Ð¾Ð² Ð´Ð»Ñ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð² ecosystem_context
        symbionts = []
        try:
            from api.storage.weaviate_storage import WeaviateStorage
            from api.storage.symbiont_service import SymbiontService

            weaviate_storage = WeaviateStorage()
            symbiont_service = SymbiontService(weaviate_storage)
            symbionts = await symbiont_service.search_symbionts(query=message_data.message, limit=5)
        except Exception as e:
            print(f"Error getting symbionts: {e}")

        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ecosystem_context Ñ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ‹Ð¼Ð¸ ÑÐ¸Ð¼Ð±Ð¸Ð¾Ð½Ñ‚Ð°Ð¼Ð¸
        ecosystem_context = format_ecosystem_context(ecosystems, location, weather=weather_context, symbionts=symbionts)

        # Format the prompt with context and message
        # ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñ‹ ÑƒÐ¶Ðµ Ð¾Ñ‚Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑÐ¼Ð¸ format_*, Ð±ÐµÐ· Ð»Ð¸ÑˆÐ½Ð¸Ñ… Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð² (KISS: reduce parameters)
        llm_context = prompt_template.format(
            local_stat=local_stat,
            external_sources=external_sources,
            conversation_summary=conversation_summary,
            recent_messages=recent_messages,
            ecosystem_context=ecosystem_context,
            graph_context=graph_context,
            message=message_data.message,
        )

        try:
            # ÐŸÑ€Ð¾ÐºÑÐ¸ ÑƒÐ¶Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÑŽ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð², Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° Ð½Ðµ Ð½ÑƒÐ¶Ð½Ð°
            # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²ÐºÐ¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ call_llm
            response_content = await call_llm(llm_context, origin="chat_message")

            # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° LLM (Ð´Ð¾ ÑƒÐ´Ð°Ð»ÐµÐ½Ð¸Ñ Ñ€Ð°Ð·Ð´ÐµÐ»Ð° Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°)
            sources: List[Dict[str, str]] = parse_sources_from_response(response_content)

            # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ñ€Ð°Ð·Ð´ÐµÐ» Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¸Ð·Ð±ÐµÐ¶Ð°Ñ‚ÑŒ Ð´ÑƒÐ±Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
            response_content = remove_sources_section_from_content(response_content)
        except (LLMPermanentError, LLMTemporaryError) as e:
            # Ð”Ð¾ ÑÑŽÐ´Ð° Ð´Ð¾Ñ…Ð¾Ð´Ð¸Ð¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ LLM Ð½Ðµ ÑÐ¼Ð¾Ð³Ð»Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ÑŒ Ð´Ð°Ð¶Ðµ Ð¿Ð¾ÑÐ»Ðµ Ð²ÑÐµÑ… Ñ€ÐµÑ‚Ñ€Ð°ÐµÐ².
            # Ð’ Ð»Ð¾Ð³Ð°Ñ… Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð´ÐµÑ‚Ð°Ð»Ð¸, Ð½Ð¾ Ð² Ñ‡Ð°Ñ‚ Ð½Ðµ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð½Ð¸ÐºÐ°ÐºÐ¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸.
            print(f"Error in send_chat_message (LLM error): {str(e)}")
            return {
                "messageId": user_message_node.id,
                "sessionId": actual_session_id,
                "message": message_data.message,
                "conceptNodeId": message_data.conceptNodeId,
                "author": message_data.author,
                "timestamp": user_message_node.timestamp,
                "response": {
                    "messageId": None,
                    "message": "",
                    "conceptNodeId": None,
                },
            }

        # Add the AI response to the concept tree
        ai_response_node = service.add_concept(
            parent_id=user_message_node.id,
            content=response_content,
            role="assistant",
            node_type="message",
            session_id=actual_session_id,
        )

        # Parse AI response to paragraphs and save for FAISS search
        try:
            await paragraph_service.save_chat_message_paragraphs(
                message_content=response_content,
                session_id=actual_session_id,
                author="assistant",
                author_id=None,
                timestamp=ai_response_node.timestamp,
            )
        except Exception as e:
            # Log error but don't fail the request
            print(f"Error saving AI response paragraphs: {e}")

        # Analysis functions are available through UI buttons (not automatic)

        # Return both the user message and AI response
        return {
            "messageId": user_message_node.id,
            "sessionId": actual_session_id,
            "message": message_data.message,
            "conceptNodeId": message_data.conceptNodeId,
            "author": message_data.author,
            "timestamp": user_message_node.timestamp,
            "response": {
                "messageId": ai_response_node.id,
                "message": ai_response_node.content,
                "conceptNodeId": ai_response_node.id,
                "sources": sources,
            },
        }
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error in send_chat_message: {str(e)}")
        print(f"message_data type: {type(message_data)}, value: {message_data}")
        import traceback

        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.get("/session/{sessionId}/history", response_model=list[ConceptNode])
async def get_chat_history(sessionId: str, request: Request):
    """
    Get the history of messages in a chat session.

    Returns all messages in the session as a flat list.
    """
    try:
        service: KBService = request.app.state.kb_service
        # Get the session node
        session_node = service.get_node(sessionId)
        if not session_node:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={"error": "SessionNotFound", "message": f"Session {sessionId} not found"},
            )

        # Get all messages in the session tree recursively
        messages = service._collect_tree_nodes(sessionId, depth=10, category=None, node_type=None, limit=1000, offset=0)

        # Filter to only message-type nodes - use getattr to safely access type attribute
        messages = [msg for msg in messages if getattr(msg, "type", None) == "message"]

        # Sort messages by timestamp to ensure chronological order
        messages.sort(key=lambda x: x.timestamp)

        return messages
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error in get_chat_history: {str(e)}")
        print(f"sessionId: {sessionId}")
        import traceback

        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.post("/concept-drag", response_model=dict)
async def drag_concept_to_chat(drag_data: ChatDragToChat, request: Request):
    """
    Handle dragging content to the chat (concepts, images, documents).

    Supports drag & drop of concept nodes, images, and text documents.
    """
    try:
        service: KBService = request.app.state.kb_service
        # Verify the session exists
        session_node = service.get_node(drag_data.sessionId)
        if not session_node:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={"error": "SessionNotFound", "message": f"Session {drag_data.sessionId} not found"},
            )

        # Handle concept node drag (existing functionality)
        if drag_data.conceptNodeId:
            concept_node = service.get_node(drag_data.conceptNodeId)
            if not concept_node:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail={
                        "error": "ConceptNodeNotFound",
                        "message": f"Concept node {drag_data.conceptNodeId} not found",
                    },
                )

            # Add the concept node to the chat session as a message
            chat_message_node = service.add_concept(
                parent_id=drag_data.sessionId,
                content=f"Ð¡ÑÑ‹Ð»ÐºÐ° Ð½Ð° ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸ÑŽ: {concept_node.content}",
                role="system",
                node_type="concept_reference",
                session_id=drag_data.sessionId,
            )
            return {
                "status": "success",
                "message": "ÐšÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð° Ð² Ñ‡Ð°Ñ‚",
                "conceptNode": chat_message_node,
                "originalConcept": concept_node,
            }

        # Handle file drag & drop
        elif drag_data.file:
            file_data = drag_data.file
            file_name = file_data.get("name", "unknown")
            file_type = file_data.get("type", "")
            file_content = file_data.get("content", "")

            if not file_content:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail={"error": "InvalidFile", "message": "File content is empty"},
                )

            # Process based on file type
            if file_type.startswith("image/"):
                # Handle image files
                message_content = f"Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾: {file_name}\n[Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ: {file_content[:50]}...]"
                node_type = "image_attachment"

            elif file_type.startswith("text/") or file_type in [
                "application/pdf",
                "application/msword",
                "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            ]:
                # Handle text documents
                # For text files, content should be the actual text
                # For binary documents (PDF, DOC), we might need additional processing
                message_content = f"Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½: {file_name}\n\nÐ¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ:\n{file_content}"
                node_type = "document_attachment"

            else:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail={"error": "UnsupportedFileType", "message": f"Unsupported file type: {file_type}"},
                )

            # Add file to chat as a message
            file_message_node = service.add_concept(
                parent_id=drag_data.sessionId,
                content=message_content,
                role="user",  # User uploaded this
                node_type=node_type,
                session_id=drag_data.sessionId,
            )

            return {
                "status": "success",
                "message": f"Ð¤Ð°Ð¹Ð» '{file_name}' ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½ Ð² Ñ‡Ð°Ñ‚",
                "fileNode": file_message_node,
                "fileType": file_type,
            }

        else:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail={"error": "InvalidRequest", "message": "Either conceptNodeId or file must be provided"},
            )
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error in drag_concept_to_chat: {str(e)}")
        print(f"drag_data type: {type(drag_data)}, value: {drag_data}")
        import traceback

        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.get("/session/current", response_model=ChatSession)
async def get_current_chat_session(request: Request, response: Response):
    """
    Get the current chat session for the user.

    Creates a new session if none exists.
    """
    try:
        # Try to get session_id from cookies
        session_id = request.cookies.get("session_id")

        if session_id:
            # Get user session (async)
            user_session = await session_manager.get_session(session_id)
            if user_session and user_session.get("chat_session_id"):
                # Get chat session
                chat_session = chat_session_service.get_session(user_session["chat_session_id"])
                if chat_session:
                    return chat_session

        # No valid session, create new ones
        # Create user session (async)
        user_session_id = await session_manager.create_session(
            {
                "user_id": "anonymous",
                "created_at": "auto",
                "message_count": 0,
                "last_activity": int(time.time()),
            }
        )

        # Create chat session
        chat_session_data = ChatSessionCreate(topic="New Chat Session", conceptTreeId=None, ecosystem=None)
        chat_session = chat_session_service.create_session(chat_session_data)

        # Link them (async)
        user_session = await session_manager.get_session(user_session_id)
        if user_session:
            user_session["chat_session_id"] = chat_session.id
            await session_manager.update_session(user_session_id, user_session)

        # Set cookie
        response.set_cookie("session_id", user_session_id, httponly=True, max_age=2592000)  # 30 days

        return chat_session
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.get("/session/{sessionId}", response_model=ChatSession)
async def get_chat_session(sessionId: str):
    """
    Get a chat session by ID.

    Returns the chat session.
    """
    try:
        session = chat_session_service.get_session(sessionId)
        if not session:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={"error": "SessionNotFound", "message": f"Session {sessionId} not found"},
            )

        return session
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error in get_chat_session: {str(e)}")
        print(f"sessionId: {sessionId}")
        import traceback

        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.get("/sessions", response_model=list[ChatSession])
async def get_all_chat_sessions():
    """
    Get all chat sessions.

    Returns all chat sessions.
    """
    try:
        # Get all chat sessions
        sessions = chat_session_service.get_all_sessions()
        return sessions
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.get("/starters", response_model=list[str])
async def get_conversation_starters():
    """
    Get conversation starters for the symbiosis project.

    Generates 3 engaging conversation starters using LLM.
    """
    try:
        starters = await generate_starters()
        return starters
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.post("/localize")
async def localize_ecosystem(request: LocalizeRequest):
    """
    Localize ecosystem for a chat session based on user location.

    Takes user coordinates and conversation text, determines the local ecosystem
    and updates the session context for better localization.
    """
    try:
        # ÐžÐ±Ñ€Ð°Ñ‚Ð½Ð¾Ðµ Ð³ÐµÐ¾ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð°Ð´Ñ€ÐµÑÐ°
        location_info = await reverse_geocode_location(request.latitude, request.longitude)

        # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ ÑÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ Ð¸ Ð»Ð¾ÐºÐ°Ñ†Ð¸ÑŽ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
        ecosystem_data = await extract_ecosystem_and_location(request.conversationText)

        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¹ Ð»Ð¾ÐºÐ°Ñ†Ð¸ÐµÐ¹ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        if location_info:
            ecosystem_data["location"] = location_info.get("display_name", f"{request.latitude}, {request.longitude}")
            ecosystem_data["coordinates"] = {"latitude": request.latitude, "longitude": request.longitude}

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐµÑÑÐ¸ÑŽ Ñ‡Ð°Ñ‚Ð°
        chat_session = chat_session_service.get_session(request.sessionId)
        if not chat_session:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail={"error": "SessionNotFound", "message": "Chat session not found"},
            )

        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        source_type = "user_provided"
        if getattr(request, "action", None) == "expand_context":
            source_type = "context_expansion"
        elif getattr(request, "action", None) == "new_branch":
            source_type = "branch_creation"

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¸ Ð² ÑÐµÑÑÐ¸Ð¸ (Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ)
        updated_location_data = {
            **ecosystem_data,
            "source": source_type,
            "timestamp": int(time.time() * 1000),  # Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ
            "action": getattr(request, "action", "localize"),
        }
        chat_session_service.update_session_location(request.sessionId, updated_location_data)

        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        logger.info(f"ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð° Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐµÑÑÐ¸Ð¸ {request.sessionId}: {updated_location_data}")

        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ ÑÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹
        location_name = location_info.get("display_name", "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ñ") if location_info else "ÐšÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹"
        ecosystem_names = [e.get("name", "") for e in ecosystem_data.get("ecosystems", [])]
        ecosystem_str = ", ".join(ecosystem_names) if ecosystem_names else "Ð¾Ð±Ñ‰Ð°Ñ ÑÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ð°"

        description = f"Ð­ÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð´Ð¸Ð°Ð»Ð¾Ð³Ð° Ð»Ð¾ÐºÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð° Ð² {location_name}. "
        if ecosystem_names:
            description += f"ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ ÑÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹: {ecosystem_str}. "
        description += "ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¿Ð¾Ð¸ÑÐºÐ° Ñ‚ÐµÐ¿ÐµÑ€ÑŒ ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ñ."

        return {
            "success": True,
            "location": location_info,
            "ecosystems": ecosystem_data.get("ecosystems", []),
            "description": description,
        }

    except Exception as e:
        log(f"Error localizing ecosystem: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.get("/symbionts/search")
async def search_symbionts(q: str = "", type: Optional[str] = None, category: Optional[str] = None, limit: int = 10):
    """
    Search for symbionts and pathogens in the knowledge base.

    Args:
        q: Search query
        type: Filter by type (symbiont, pathogen, commensal, parasite)
        category: Filter by category (bacteria, virus, fungus, etc.)
        limit: Maximum number of results

    Returns:
        List of matching symbionts/pathogens
    """
    try:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ðº Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ñƒ Weaviate Ñ‡ÐµÑ€ÐµÐ· Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐµÑ€Ð²Ð¸ÑÑ‹
        # Ð’ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸ ÑÑ‚Ð¾ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð²Ð½ÐµÐ´Ñ€ÐµÐ½Ð¾ Ñ‡ÐµÑ€ÐµÐ· dependency injection
        from api.storage.weaviate_storage import WeaviateStorage
        from api.storage.symbiont_service import SymbiontService

        weaviate_storage = WeaviateStorage()
        symbiont_service = SymbiontService(weaviate_storage)

        # Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ Ð¿Ð¾Ð¸ÑÐº
        symbionts = await symbiont_service.search_symbionts(
            query=q, type_filter=type, category_filter=category, limit=limit
        )

        # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð² JSON-ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚
        results = []
        for symbiont in symbionts:
            results.append(
                {
                    "id": symbiont.id,
                    "name": symbiont.name,
                    "scientific_name": symbiont.scientific_name,
                    "type": symbiont.type,
                    "category": symbiont.category,
                    "interaction_type": symbiont.interaction_type,
                    "biochemical_role": symbiont.biochemical_role,
                    "risk_level": symbiont.risk_level,
                    "prevalence": symbiont.prevalence,
                    "detection_confidence": symbiont.detection_confidence,
                }
            )

        return {"success": True, "query": q, "total": len(results), "symbionts": results}

    except Exception as e:
        log(f"Error searching symbionts: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.post("/search/web")
async def search_web(query: str = Body(...)):
    """
    Perform web search for the given query.

    Args:
        query: Search query

    Returns:
        Search results
    """
    try:
        results = await web_search_service.search_and_extract(query, max_results=3)

        if not results:
            return {"results": "ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¿Ð¾Ð¸ÑÐºÐ°"}

        formatted_results = []
        for i, result in enumerate(results, 1):
            title = result.get("title", "Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ")
            content = result.get("content", "")[:500]
            url = result.get("url", "")

            formatted_results.append(f"{i}. {title}")
            if url:
                formatted_results.append(f"   Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº: {url}")
            formatted_results.append(f"   {content}")
            formatted_results.append("")

        return {"results": "\n".join(formatted_results)}

    except Exception as e:
        log(f"Error performing web search: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


@router.post("/search/books")
async def search_books(query: str = Body(...), session_id: Optional[str] = None):
    """
    Search for books related to the query and index them for the session.

    Args:
        query: Search query
        session_id: Optional chat session ID for book indexing

    Returns:
        Book search results with indexing information
    """
    try:
        # Perform book search and indexing
        context = await search_books_for_message(query, web_search_service, session_id)

        return {
            "query": query,
            "session_id": session_id,
            "books_context": context,
            "indexed": session_id is not None,
            "timestamp": int(time.time() * 1000),
        }

    except Exception as e:
        log(f"Error performing book search: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail={"error": "InternalError", "message": str(e)},
        )


async def search_books_for_message(message: str, web_search_service, session_id: Optional[str] = None) -> str:
    """
    Search for books related to the message content and index them for the session.

    Args:
        message: User message to search books for
        web_search_service: Web search service instance
        session_id: Chat session ID for book indexing

    Returns:
        Formatted context string with book information
    """
    try:
        # Create book-focused search query
        book_query = f"books about {message}"

        # Use the web search service to find book information
        results = await web_search_service.search_and_extract(book_query, max_results=5)

        if not results:
            return ""

        context_parts = []
        context_parts.append("### Ð˜Ð· ÐºÐ½Ð¸Ð³:")

        indexed_books = []
        for i, result in enumerate(results, 1):
            title = result.get("title", "Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ")
            content = result.get("content", "")[:1000]  # Longer excerpts for books
            url = result.get("url", "")

            # Create book index entry
            book_entry = {
                "id": f"book_{session_id}_{i}_{int(time.time())}",
                "title": title,
                "content": content,
                "url": url,
                "indexed_at": int(time.time() * 1000),
                "session_id": session_id,
                "search_query": message,
            }
            indexed_books.append(book_entry)

            # Format as book reference
            context_parts.append(f"ðŸ“š {title}")
            if url:
                context_parts.append(f"   Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº: {url}")
            context_parts.append(f"   {content}")
            context_parts.append("")

        # TODO: Save indexed_books to database for future searches within session
        # This will allow searching within already indexed books
        if session_id and indexed_books:
            try:
                # Save to session context for now (temporary solution)
                # In future: create proper books table and indexing
                chat_session = chat_session_service.get_session(session_id)
                if chat_session:
                    current_books = chat_session.indexed_books or []
                    current_books.extend(indexed_books)
                    # Keep only last 50 books per session to avoid memory issues
                    if len(current_books) > 50:
                        current_books = current_books[-50:]
                    chat_session_service.update_session_books(session_id, current_books)
            except Exception as e:
                log(f"Error saving indexed books: {e}")

        return "\n".join(context_parts)

    except Exception as e:
        log(f"Error searching books: {e}")
        return ""


# Removed automatic analysis - now handled through UI buttons
